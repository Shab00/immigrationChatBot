{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1633,
     "status": "ok",
     "timestamp": 1728740638966,
     "user": {
      "displayName": "Bashaar Dhoot",
      "userId": "04066267376811464441"
     },
     "user_tz": -60
    },
    "id": "xD8ly-xJExrQ"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import logging\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_legislation_content(url, output_file, log_file):\n",
    "    # Set up logging\n",
    "    logging.basicConfig(filename=log_file, level=logging.ERROR, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    # Set up Selenium WebDriver for Firefox\n",
    "    options = Options()\n",
    "    options.headless = True\n",
    "    service = Service('/opt/homebrew/bin/geckodriver')  # Adjust the path to your geckodriver\n",
    "    driver = webdriver.Firefox(service=service, options=options)\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Load the page with Selenium\n",
    "        driver.get(url)\n",
    "        time.sleep(3)  # Wait for the page to fully load\n",
    "        \n",
    "        # Step 2: Get the page source and parse it with BeautifulSoup\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        # Step 3: Extract all links to follow\n",
    "        links = soup.find_all('a', href=True)\n",
    "        base_url = \"https://www.legislation.gov.uk\"\n",
    "        \n",
    "        # Step 4: Iterate through each link and scrape content\n",
    "        with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile)\n",
    "            csvwriter.writerow(['Section', 'Title', 'Paragraph'])\n",
    "            \n",
    "            for link in links:\n",
    "                href = link['href']\n",
    "                if href.startswith('/ukpga/2016/19/'):\n",
    "                    full_url = base_url + href\n",
    "                    driver.get(full_url)\n",
    "                    time.sleep(3)  # Wait for the page to fully load\n",
    "                    page_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                    content = page_soup.find('div', id='viewLegContents')\n",
    "                    \n",
    "                    if not content:\n",
    "                        logging.error(f\"No content found on {full_url}\")\n",
    "                        continue\n",
    "                    \n",
    "                    section_title = content.find('h2').get_text(strip=True) if content.find('h2') else 'No Title'\n",
    "                    paragraphs = content.find_all('p')\n",
    "                    \n",
    "                    for paragraph in paragraphs:\n",
    "                        csvwriter.writerow([href, section_title, paragraph.get_text(strip=True)])\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "# Example usage\n",
    "url = \"https://www.legislation.gov.uk/ukpga/2016/19/contents\"\n",
    "output_file = \"legislation_content.csv\"\n",
    "log_file = \"scrape_errors.log\"\n",
    "scrape_legislation_content(url, output_file, log_file)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOJHU65nG+auG2Q7NQ6sJ8D",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
