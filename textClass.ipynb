{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15191,
     "status": "ok",
     "timestamp": 1731152367147,
     "user": {
      "displayName": "Bashaar Dhoot",
      "userId": "04066267376811464441"
     },
     "user_tz": 0
    },
    "id": "0a7-xJaCeUHv",
    "outputId": "f48c5bd1-b986-4c52-86b7-9f2a2c0d67c6"
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets langchain sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zr1mO1Nps2S1",
    "outputId": "2b98a6b8-a0de-4d7b-f73b-1e8b0777c223"
   },
   "outputs": [],
   "source": [
    "!pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13306,
     "status": "ok",
     "timestamp": 1730749469605,
     "user": {
      "displayName": "Bashaar Dhoot",
      "userId": "04066267376811464441"
     },
     "user_tz": 0
    },
    "id": "ZbzRxp_gtM1Y",
    "outputId": "0a4fa00d-2bee-42a5-e819-8700fb8d22ad"
   },
   "outputs": [],
   "source": [
    "!pip install ray[tune]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3142,
     "status": "ok",
     "timestamp": 1730746331311,
     "user": {
      "displayName": "Bashaar Dhoot",
      "userId": "04066267376811464441"
     },
     "user_tz": 0
    },
    "id": "wY11qhQfhHzo",
    "outputId": "736ea0e9-0b97-4c61-908e-2123ef3bfea0"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jj3E61Z0VPeD"
   },
   "source": [
    "mport necessary libraries:\n",
    "\n",
    "*   **`pandas`**: For data manipulation.\n",
    "*   **`transformers`**: For using pre-trained models.\n",
    "*   **`torch`**: For tensor operations.\n",
    "*   **`sklearn.model_selection`**: For splitting data.\n",
    "* **`ray.tune`**: For hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "obXKVqAfeUHw"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, pipeline, EarlyStoppingCallback\n",
    "import transformers\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m00xQ499Vy4v"
   },
   "source": [
    "Load the dataset from the specified CSV file into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1730746349283,
     "user": {
      "displayName": "Bashaar Dhoot",
      "userId": "04066267376811464441"
     },
     "user_tz": 0
    },
    "id": "CXl7TUNBeUHx",
    "outputId": "370555a9-12bf-4c62-b657-699943a5ac6c"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/cleanerData.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8u3cKlr5V23S"
   },
   "source": [
    "Rename specific columns for better readability and consistency.\n",
    "* The `Section` column is renamed to `Title`.\n",
    "* The `Paragraph` column is renamed to `Content`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ielGbnW_TQW"
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'Section': 'Title'}, inplace=True)\n",
    "\n",
    "df.rename(columns={'Paragraph': 'Content'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Rez67H_V7bq"
   },
   "source": [
    "Concatenate `Title` and `Content` into a new `text` column, and remove rows with missing text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MrGKtYnEn0E9"
   },
   "outputs": [],
   "source": [
    "df['text'] = df['Title'] + ' ' + df['Content']\n",
    "df.dropna(subset=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kwNVJFmFtFIw"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKil_mwoWJ-5"
   },
   "source": [
    "Convert all text to lowercase and remove leading/trailing whitespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNwoLsxan7fz"
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda text: text.lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 621,
     "status": "ok",
     "timestamp": 1730746363297,
     "user": {
      "displayName": "Bashaar Dhoot",
      "userId": "04066267376811464441"
     },
     "user_tz": 0
    },
    "id": "DczZbyuVqz5w",
    "outputId": "270aa47e-a5dd-4493-debe-8b543fb415ea"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QiWlOdbXWO09"
   },
   "source": [
    "# Model Initialization and Pipeline Setup\n",
    "\n",
    "This section initializes a pre-trained BERT model, sets up a text classification pipeline, and applies the model to predict classes for the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1456,
     "status": "ok",
     "timestamp": 1730746368951,
     "user": {
      "displayName": "Bashaar Dhoot",
      "userId": "04066267376811464441"
     },
     "user_tz": 0
    },
    "id": "bjoTbO9vtJkS",
    "outputId": "af5e98b5-03cd-41b6-ca92-8aa2e799804b"
   },
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(df['Content'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBuEmX5lWXow"
   },
   "source": [
    "Load the tokenizer and a pre-trained BERT model for sequence classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xrg8bsNQtNNG"
   },
   "outputs": [],
   "source": [
    "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6cmNqhpWbKO"
   },
   "source": [
    "Create a text classification pipeline using the loaded model and tokenizer.\n",
    "\n",
    "*   Utilize GPU if available (`device=0`), else use CPU (`device=-1`).\n",
    "*   Set `truncation=True` and `max_length=512` to handle long sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16254,
     "status": "ok",
     "timestamp": 1730746394228,
     "user": {
      "displayName": "Bashaar Dhoot",
      "userId": "04066267376811464441"
     },
     "user_tz": 0
    },
    "id": "QJx4ne0FtSTU",
    "outputId": "086cb10f-a9ad-489a-c33d-5baba550f5ad"
   },
   "outputs": [],
   "source": [
    "def classify_text(text):\n",
    "    result = classifier(text)[0]\n",
    "    return result['label']\n",
    "\n",
    "df['predicted_class'] = df['text'].apply(classify_text)\n",
    "\n",
    "print(df[['text', 'predicted_class']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcJf5O66XXbX"
   },
   "source": [
    "List the unique labels in the predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 239,
     "status": "ok",
     "timestamp": 1730746400635,
     "user": {
      "displayName": "Bashaar Dhoot",
      "userId": "04066267376811464441"
     },
     "user_tz": 0
    },
    "id": "be0egPr5Rk-4",
    "outputId": "f0720a96-df47-4660-8d52-2c75612951a1"
   },
   "outputs": [],
   "source": [
    "df['predicted_class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 248,
     "status": "ok",
     "timestamp": 1730746402734,
     "user": {
      "displayName": "Bashaar Dhoot",
      "userId": "04066267376811464441"
     },
     "user_tz": 0
    },
    "id": "JAnJstsJRo5u",
    "outputId": "fc3d9138-1d76-4590-f315-24fd9625ef39"
   },
   "outputs": [],
   "source": [
    "print(len(df['predicted_class'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGLtpc0rXnjq"
   },
   "source": [
    "# Data Splitting and Tokenization\n",
    "\n",
    "This section prepares the data for training by converting labels to numerical IDs, splitting the data into training and validation sets, and tokenizing the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2YNFM1sThk5g"
   },
   "outputs": [],
   "source": [
    "all_labels = df['predicted_class'].tolist()\n",
    "unique_labels = pd.Series(all_labels).unique()\n",
    "label_mapping = {label: i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "def convert_labels_to_ids(labels):\n",
    "    return [label_mapping[label] for label in labels]\n",
    "\n",
    "all_texts = df['text'].tolist()\n",
    "all_labels_numerical = convert_labels_to_ids(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 1549,
     "status": "ok",
     "timestamp": 1730746452954,
     "user": {
      "displayName": "Bashaar Dhoot",
      "userId": "04066267376811464441"
     },
     "user_tz": 0
    },
    "id": "LoeOsxMxhu4a",
    "outputId": "aaa6d336-7a4c-4875-c13f-312ece28cab6"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDTe2GImXt49"
   },
   "source": [
    "Split the data into training and validation sets (80/20 split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_KF9h2ChwQg"
   },
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    all_texts, all_labels_numerical, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sBHMm6_hiBpH"
   },
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138,
     "referenced_widgets": [
      "cc2fdc900171420896ed2e501552638e",
      "1ea1a7a9f04a4f40b4c0cbcf21fbc284",
      "ccb6dfa48daa46eba997fa44ac46e2a7",
      "7250117f89e6440c980d33aef55a2716",
      "78d2004f778a482390e4b4b4c8954091",
      "8a5e66adeabc496f89186309c49e52cb",
      "05a710d55df94154a2899a3599c07e18",
      "caac78b8bd2d4119bb3d225d1a65852d",
      "7014e546c1304e029a95efbcfcdb9596",
      "530d478734054d72a636cef8767a044d",
      "e045bdea5fb6490a8d745d5f18e2f61a",
      "fc63b593fc0943b0b66f00bb1f8621b0",
      "1e8b3bee73d845049cadd4ceb4fd6e64",
      "7ad7c5047f564aad938cce33fe3075c8",
      "e9e02c7c147e47b19cfdd50baad0bedc",
      "f108c67074cf429c905f7156103b2449",
      "ebd838af1733416fbeebfef64d8229da",
      "a0ee35171208486c897ad71ed28ff7b5",
      "6902d9e8bd824e8f80418c603c87d9d3",
      "93e64f67179a436e94ac33304be136b7",
      "f43547186daa49a6a12345d68b26dbd8",
      "e894899d980140cca173f799c24233a1"
     ]
    },
    "executionInfo": {
     "elapsed": 5064,
     "status": "ok",
     "timestamp": 1730746539992,
     "user": {
      "displayName": "Bashaar Dhoot",
      "userId": "04066267376811464441"
     },
     "user_tz": 0
    },
    "id": "op6TYQvyh7yR",
    "outputId": "1c4869ae-3993-44fd-fe67-503ec57dba4d"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "train_dataset = datasets.Dataset.from_dict({\"text\": train_texts, \"label\": train_labels})\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "val_dataset = datasets.Dataset.from_dict({\"text\": val_texts, \"label\": val_labels})\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJ9GO9JSX0k5"
   },
   "source": [
    "# Model Training\n",
    "\n",
    "This section defines the model, training arguments, and trainer. The model is then trained on the preprocessed training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "executionInfo": {
     "elapsed": 234312,
     "status": "ok",
     "timestamp": 1730749359108,
     "user": {
      "displayName": "Bashaar Dhoot",
      "userId": "04066267376811464441"
     },
     "user_tz": 0
    },
    "id": "IP2knJ2biAOB",
    "outputId": "da2f41ea-c019-455a-a5da-72082b22fe0a"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", num_labels=len(unique_labels)\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",         \n",
    "    per_device_train_batch_size=8,  \n",
    "    per_device_eval_batch_size=64,  \n",
    "    num_train_epochs=4,              \n",
    "    learning_rate=2e-5,           \n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "\n",
    "    metric_for_best_model=\"eval_loss\",  \n",
    "    greater_is_better=False, \n",
    "    evaluation_strategy=\"epoch\",     \n",
    "    save_strategy=\"epoch\",           \n",
    "    load_best_model_at_end=True,   \n",
    "    push_to_hub=False,             \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjH2hwW9YHuq"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "The model training process has been completed, with the following results achieved after 4 epochs:\n",
    "\n",
    "*   **Global Steps:** 236\n",
    "*   **Training Loss:** 0.4968\n",
    "*   **Training Time:** 232.36 seconds\n",
    "*   **Samples per Second:** 8.125\n",
    "*   **Steps per Second:** 1.016\n",
    "*   **Total FLOPS:** 496,775,973,273,600\n",
    "* **Epoch:** 4.0\n",
    "\n",
    "**Analysis:**\n",
    "\n",
    "The model's training concluded with a final training loss of approximately `0.4968`. This value indicates the average difference between the model's predictions and the actual labels during the training phase. A loss of `0.4968`, while not extremely low, is indicative of a model that has learned to some degree.\n",
    "The model has processed an average of 8.125 samples per second, showing a moderate speed of processing. The rate of 1.016 training steps per second indicates that the model is progressing at a steady pace. The training time of 232.36 seconds was used to complete the 4 training epochs.\n",
    "The total `FLOPS` (Floating Point Operations) represent the computational load involved in the training process.\n",
    "\n",
    "**Implications for the Immigration Chatbot:**\n",
    "\n",
    "Given these results, the text classification model for the immigration chatbot has shown some promising learning, achieving a loss that demonstrates it has learned meaningful patterns in the data. The model is working properly.\n",
    "\n",
    "**Conclusion:**\n",
    "In conclusion, the training phase for the immigration chatbot's text classification model was successful. The model shows potential, but further evaluation and fine-tuning are required to ensure its reliability in real-world scenarios."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
